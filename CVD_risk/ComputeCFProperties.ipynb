{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11f473c-1b38-4d20-8def-5388e034f8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#Import necessary modules\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics.pairwise import cosine_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88a47c7-ad60-4fea-af29-90e3391007e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=pd.read_csv(r'.\\F.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59263a0-9f1c-4dc5-8321-f8f4c91a1b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('FACTUALS')\n",
    "f=pd.read_csv(r'.\\F.csv') #load factuals\n",
    "f=f.drop('sogliaFRS',axis=1) #drop output class (if present)\n",
    "print(f.shape)\n",
    "print(f.head())\n",
    "\n",
    "print('COUNTERFACTUALS-1')\n",
    "c1=pd.read_csv(r'.\\CF_31.csv') #load counterfactual explanations of class 1 (high->low transition)\n",
    "print(c1.head())\n",
    "c1=c1.drop('sogliaFRS',axis=1) #drop output class (if present)\n",
    "c1.iloc[:, :4] = c1.iloc[:, :4].round(0).abs()\n",
    "\n",
    "\n",
    "print('COUNTERFACTUALS-2') #load counterfactual explanations of class 1 (high->moderate transition)\n",
    "c2=pd.read_csv(r'.\\CF_32.csv')\n",
    "print(c2.head())\n",
    "c2=c2.drop('sogliaFRS',axis=1) #drop output class (if present)\n",
    "c2.iloc[:, :4] = c2.iloc[:, :4].round(0).abs()\n",
    "\n",
    "for col in f.columns[:4]: #convert categoricals\n",
    "    f_MUCH_double[col] = f[col].astype('category')\n",
    "    c1[col] = c1[col].astype('category')\n",
    "    c2[col] = c2[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d4fd8f-11d1-43f6-a096-55772c1e11e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=f_MUCH_double.shape[1] #number of input features\n",
    "h=f_MUCH_double.select_dtypes(include=['category']).shape[1]#number of categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e35751-90de-4b73-8057-613f2e3f7665",
   "metadata": {},
   "source": [
    "### Mixed distance\n",
    "\n",
    "d(x_i,x_j)= (h/m)* HammingDistance(x_i,x_j)+((m-h)/m)* CosineDistance(x_i,x_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c50a4ed-0e57-4b06-a5d1-c09f009194d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMixedDistance(row1, row2,h,m):   \n",
    "    '''Compute mixed distance between 2 observations with both categorical and numerical attributes\n",
    "    Parameters:\n",
    "    row1: observartion 1\n",
    "    row2: observation 2\n",
    "    h: number of categorical features\n",
    "    m: total number of input features\n",
    "\n",
    "    Returns: \n",
    "    d1+d2: weighted sum of Hamming and Cosine distances\n",
    "    '''\n",
    "    \n",
    "    row1_cat = row1[:h]\n",
    "    row2_cat = row2[:h]\n",
    "    row1_num=np.array(row1[ h:]).reshape(1, -1)\n",
    "    row2_num=np.array(row2[h:]).reshape(1, -1)\n",
    "    hammingDist=sum(el1 != el2 for el1, el2 in zip(row1_cat, row2_cat))\n",
    "    cosineDist = cosine_distances(row1_num, row2_num)\n",
    "    d1=(h/m)*hammingDist\n",
    "    d2= ((m-h)/m)*cosineDist\n",
    "    \n",
    "    return d1+d2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8ff4da-5369-4591-844f-f1fd7cbe33f2",
   "metadata": {},
   "source": [
    "## PROXIMITY\n",
    "Average distance between \n",
    "x and the counterfactual x (the lower the better)d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1486f504-6dca-4689-9e8d-55b88b04845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f_MUCH_double_values = f_MUCH_double.values\n",
    "df_c1_MUCH_double_values = c1_MUCH_double.values\n",
    "df_c2_MUCH_double_values = c2_MUCH_double.values\n",
    "\n",
    "# Calculate the distance between each factual x and each corresponding counterfactual explanation of class 1\n",
    "distances = [computeMixedDistance(row1, row2,h,m) for row1, row2 in zip(f.values , c1.values )]\n",
    "# Calculate the average distance\n",
    "average_distance = np.mean(distances)\n",
    "print(\"Proximity F-c1:\", average_distance)\n",
    "print('-----------')\n",
    "# Calculate the distance between each factual x and each corresponding counterfactual explanation of class 2\n",
    "distances = [computeMixedDistance(row1, row2,h,m) for row1, row2 in zip(f.values , c2.values)]\n",
    "average_distance = np.mean(distances)\n",
    "print(\"Proximity F-c2:\", average_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155a2abe-1017-4c56-9852-88b4baf9ef36",
   "metadata": {},
   "source": [
    "## SPARSITY\n",
    "Average number of features changed between a counterfactual xâ€² and x (the lower the better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c12628c-8674-499e-a6e8-3ff0efefea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSparsity(df1,df2,m):\n",
    "    '''Compute average number of features changed\n",
    "    Parameters:\n",
    "    df1: full set of factual observations\n",
    "    df2: corresponding counterfactual explanations\n",
    "    m: number of input features\n",
    "   \n",
    "    Returns: \n",
    "    distance: average number of times two features are not equal (tolerance = 10% of the factual observation)\n",
    "    '''\n",
    "    total_distance = 0\n",
    "    \n",
    "    for index in range(len(df1)): # Iterate over each factual row\n",
    "        row1 = df1.iloc[index]\n",
    "        row2 = df2.iloc[index]\n",
    "        dist = 0\n",
    "        \n",
    "        for col in df1.columns:  # Iterate over each feature\n",
    "            \n",
    "            x1 = row1[col]\n",
    "            x2 = row2[col]\n",
    "            # Calculate tolerance (10% of the factual value x1)\n",
    "            tolerance = 0.1 * x1\n",
    "            \n",
    "            # Compare each feature value\n",
    "            if abs(x1 - x2) > tolerance: #if the distance between the 2 values is greater than the tolerance the 2 values are considered different and the distance increases by 1\n",
    "                dist = 1\n",
    "            else:\n",
    "                dist=0\n",
    "\n",
    "            total_distance += dist      \n",
    "    \n",
    "    distance=total_distance/(len(df1)*m)\n",
    "    return distance\n",
    "\n",
    "print(\"Sparsity F-c1:\", computeSparsity(f,c1,m)) #the lower the better\n",
    "print(\"Sparsity F-c2:\", computeSparsity(f,c2,m))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb5bace-58d3-4f78-b6c3-a50da7db2a9a",
   "metadata": {},
   "source": [
    "## ROBUSTNESS (IMPLAUSIBILITY)\n",
    "It can be computed in 2 ways (the lower, the better):\n",
    "<li> Distance of x' from the closest instance \n",
    "in the reference set X   (e.g., test set) </li>\n",
    "<li> <b> OR </b> Distance of x' from the barycenter of the target class </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5453509-52f3-417e-b7ba-7ea3354b0307",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv(\"Test.csv\")\n",
    "test_df=test_df.rename(columns={\"tot_chol_mmol_L_\": \"totChol\"})\n",
    "\n",
    "def computeImplausibility(test_df, cf,h,m):\n",
    "    '''Compute average  distance of x' of the counterfactuals from the closest instance in the reference set X\n",
    "    Parameters:\n",
    "    test_df: reference set\n",
    "    cf: set of counterfactual explanations\n",
    "    h: number of categorical features\n",
    "    m: number of input features\n",
    "    Returns: \n",
    "    average_min_distance: average of the minimum distances across the number of counterfactuals\n",
    "    '''\n",
    "    distances = []\n",
    "    test_df=test_df.iloc[:, :-1]\n",
    "    \n",
    "    for i, row1 in cf.iterrows():  # Iterate over each counterfactual in cf\n",
    "        # Compute distances from the i-th cf to all the rows in the test set using the mixed distance\n",
    "        dists = test_df.apply(lambda row2: computeMixedDistance(row1.values, row2.values,h,m), axis=1)\n",
    "        # Take the minimum distance\n",
    "        min_dist = dists.min()\n",
    "        distances.append(min_dist)\n",
    "    \n",
    "    # Compute the average of the minimum distances across the number of counterfactuals\n",
    "    average_min_distance = np.mean(distances)\n",
    "    return average_min_distance\n",
    "\n",
    "print(\"Implausibility F-c1:\", computeImplausibility(test_df, c1,h,m))  #the lower the better\n",
    "print(\"Implausibility F-c2:\", computeImplausibility(test_df, c2,h,m))\n",
    "print('------------------------')\n",
    "\n",
    "bar_df = pd.read_csv(\"Barycenters.csv\") #load barycenters\n",
    "bar_df.iloc[:, :4] = bar_df.iloc[:, :4].round(0).abs()\n",
    "for col in bar_df.columns[:4]:\n",
    "    bar_df[col] = bar_df[col].astype('category')\n",
    "\n",
    "distances = [computeMixedDistance(row, bar_df.iloc[0,:].values,h,m) for row in c1.values ]\n",
    "average_distance = np.mean(distances)\n",
    "print(\"Implausibility(BARYCENTER) F-c1:\", average_distance)\n",
    "distances = [computeMixedDistance(row, bar_df.iloc[1,:].values,h,m) for row in c2.values]\n",
    "average_distance = np.mean(distances)\n",
    "print(\"Implausibility(BARYCENTER) F-c2:\", average_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cf4a99-1f65-43e3-b72b-253927581969",
   "metadata": {},
   "source": [
    "## DIVERSITY\n",
    "Average distance between \n",
    "the set of found counterfactual (the higher, the better)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d231fa8-e14e-4237-9cfc-76d81cccb50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeDiversity (cf, h,m ): \n",
    "    '''Compute average between pairs of counterfactuals x' and x''\n",
    "    Parameters:\n",
    "    cf: set of counterfactual explanations of a certain class\n",
    "    h: number of categorical features\n",
    "    m: number of input features\n",
    "    Returns: \n",
    "    diversity: average of the distances between all pairs of counterfactual explanations\n",
    "    '''\n",
    "    dist=0\n",
    "    for i in range(len(cf)):\n",
    "        for j in range(len(cf)):\n",
    "            row1 = cf[i]\n",
    "            row2 = cf[j]\n",
    "            dist += computeMixedDistance(row1, row2,h,m)\n",
    "    diversity=dist/(len(cf)*len(cf))\n",
    "    return diversity\n",
    "\n",
    "print(\"Diversity F-c1:\", computeDiversity(c1.values,h,m))  #the higher the better\n",
    "print(\"Diversity F-c2:\", computeDiversity(c2.values,h,m))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8c0a96-7563-476f-8c9b-93492dc27082",
   "metadata": {},
   "source": [
    "## DISCRIMINATIVE POWER\n",
    "It measure the ability to distinguish the set of counterfactuals from the points in the factual class (e.g., points from the training set) using a binary classifier (the higher, the better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2eaeaf-22d1-40a0-ab82-b82109c6a0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=pd.read_csv(r\"Training.csv\",sep=',') #read training set\n",
    "training_set=training_set.rename({'tot_chol_mmol_L_': 'totChol'},axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79f5516-20ed-4f02-b514-0ebd9c720212",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract desired factual class\n",
    "real_positives=training_set[training_set['sogliaFRS']==3]\n",
    "real_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac6d02b-a8c8-44fb-8f0e-610a4c384205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminative_power(X,y,neighbors, n_cv):\n",
    "    # Split into training and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42, stratify =y)\n",
    "    scaler = StandardScaler()\n",
    "    # Fit only on X_train\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    # Scale both X_train and X_test\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    print('Cross-validation_scores')\n",
    "    print(scores)\n",
    "  \n",
    "    print('Discriminative Power:')\n",
    "    print(scores.mean())   # average the five scores.\n",
    "    # choose k between 1 to 31\n",
    "    k_range = range(1, 31)\n",
    "    k_scores = []\n",
    "    \n",
    "    for k in k_range:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        scores = cross_val_score(knn, X_train, y_train, cv=5, scoring='accuracy')\n",
    "        k_scores.append(scores.mean())\n",
    "    plt.plot(k_range, k_scores)\n",
    "    plt.xlabel('Value of K for KNN')\n",
    "    plt.ylabel('Cross-Validated Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36349db5-9cdf-40a2-abf8-512812b756e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Class 1')\n",
    "df_1=pd.concat([real_positives,c1],ignore_index=True)\n",
    "df_1 = df_1.sample(frac=1).reset_index(drop=True) #shuffle\n",
    "y=df_DICE_double['sogliaFRS']\n",
    "X=df_DICE_double.drop(['sogliaFRS'],axis=1)\n",
    "discriminative_power(X,y,neighbors=5, n_cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63890df7-00b0-4fe2-bd45-401b2934aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Class 2')\n",
    "df_2=pd.concat([real_positives,c2],ignore_index=True)\n",
    "df_2 = df_2.sample(frac=1).reset_index(drop=True) #shuffle\n",
    "y=df_DICE_double['sogliaFRS']\n",
    "X=df_DICE_double.drop(['sogliaFRS'],axis=1)\n",
    "discriminative_power(X,y,neighbors=5, n_cv=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
